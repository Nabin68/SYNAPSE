<div align="center">

# ğŸ§  SYNAPSE

### **A Modular AI Assistant with Tools, Memory, and Real-Time Streaming**

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg)](https://www.python.org/)
[![LangGraph](https://img.shields.io/badge/LangGraph-Enabled-green.svg)](https://langchain-ai.github.io/langgraph/)
[![Streamlit](https://img.shields.io/badge/Streamlit-Powered-red.svg)](https://streamlit.io/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)

*Built with LangGraph, LangChain, and Cohere*

[Features](#-features) â€¢ [Architecture](#%EF%B8%8F-architecture) â€¢ [Installation](#%EF%B8%8F-setup) â€¢ [Usage](#-usage) â€¢ [Roadmap](#-roadmap)

---

</div>

## ğŸ“– Overview

**SYNAPSE** is a graph-based AI assistant that combines the power of **LangGraph orchestration**, **tool-aware reasoning**, and **conversational memory** into a sleek Streamlit interface. Built for developers who want to create intelligent, context-aware chatbots with minimal friction.

### Why SYNAPSE?

- ğŸ¯ **Modular Design** â€” Easy to extend with new tools and capabilities
- ğŸ”„ **Graph-Based Reasoning** â€” Sophisticated agent orchestration using LangGraph
- ğŸ’¾ **Conversational Memory** â€” Maintains context across multi-turn conversations
- âš¡ **Real-Time Streaming** â€” Token-by-token response generation
- ğŸ› ï¸ **Tool Integration** â€” Web search, stock prices, and custom tools
- ğŸ¨ **Clean UI** â€” Professional Streamlit interface with session management

---

## âœ¨ Features

<table>
<tr>
<td width="50%">

### ğŸ¤– **AI Core**
- Graph-based agent orchestration with LangGraph
- Tool-enabled LLM (ChatCohere)
- Conditional tool execution & routing
- In-memory conversational state management

</td>
<td width="50%">

### ğŸ¨ **User Experience**
- Streamlit-based chat interface
- Multi-threaded conversation switching
- Session state management
- Token-level streaming responses

</td>
</tr>
<tr>
<td width="50%">

### ğŸ› ï¸ **Tools & Integrations**
- Web search (DuckDuckGo)
- Stock price lookup
- Structured data retrieval
- Extensible tool architecture

</td>
<td width="50%">

### ğŸ’¾ **Memory & State**
- LangGraph checkpoint system
- Cross-session memory persistence
- Thread-based conversation management
- Context-aware responses

</td>
</tr>
</table>

---

## ğŸ—ï¸ Architecture

SYNAPSE follows a clean, modular architecture that separates concerns for maximum flexibility:

```mermaid
graph TB
    A[Streamlit Frontend] -->|User Input| B[LangGraph StateGraph]
    B -->|Process| C[ChatCohere LLM]
    C -->|Decision| D{Tool Needed?}
    D -->|Yes| E[ToolNode]
    D -->|No| F[Direct Response]
    E -->|Execute| G[Tool Functions]
    G -->|Results| C
    C -->|Stream| A
    B ---|Memory| H[(Checkpoint Store)]
    
    style A fill:#ff6b6b
    style B fill:#4ecdc4
    style C fill:#45b7d1
    style E fill:#96ceb4
    style H fill:#ffeaa7
```

### Component Breakdown

| Component | File | Responsibility |
|-----------|------|----------------|
| **Backend** | `Backend.py` | LangGraph state management, LLM orchestration, tool routing |
| **Frontend** | `Frontend.py` | Streamlit UI, conversation management, streaming display |
| **Tools** | `Tools.py` | Tool definitions, web search, stock prices, custom functions |

---

## ğŸ“‚ Project Structure

```
synapse-ai/
â”‚
â”œâ”€â”€ ğŸ“„ Backend.py          # Core agent logic & graph orchestration
â”œâ”€â”€ ğŸ¨ Frontend.py         # Streamlit chat interface
â”œâ”€â”€ ğŸ› ï¸ Tools.py            # Tool definitions & implementations
â”œâ”€â”€ ğŸ“‹ requirements.txt    # Python dependencies
â”œâ”€â”€ ğŸ” .env.example        # Environment variable template
â””â”€â”€ ğŸ“– README.md           # Project documentation
```

---

## âš™ï¸ Setup

### Prerequisites

- **Python 3.8+**
- **Cohere API Key** ([Get one here](https://cohere.com/))

### 1ï¸âƒ£ Clone the Repository

```bash
git clone https://github.com/Nabin68/SYNAPSE.git
cd SYNAPSE
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

**Required packages:**
```txt
langchain
langchain-cohere
langgraph
streamlit
python-dotenv
duckduckgo-search
yfinance
```

### 3ï¸âƒ£ Configure Environment

Create a `.env` file in the project root:

```env
COHERE_API_KEY=your_cohere_api_key_here
```

> ğŸ’¡ **Tip:** Copy `.env.example` to `.env` and fill in your API key

---

## ğŸš€ Usage

### Running the Application

```bash
streamlit run Frontend.py
```

The application will open in your default browser at `http://localhost:8501`

### Using the Chat Interface

1. **Start Chatting** â€” Type your message in the input box
2. **Watch Live Responses** â€” See the AI respond in real-time with streaming
3. **Switch Conversations** â€” Use the sidebar to create or switch between threads
4. **Tool Usage** â€” The AI automatically uses tools when needed (search, stock prices, etc.)

### Example Interactions

```
User: What's the current price of Apple stock?
ğŸ§  SYNAPSE: [Uses stock price tool]
      The current price of AAPL is $195.83...

User: Search for the latest AI news
ğŸ§  SYNAPSE: [Uses web search tool]
      Here are the latest developments in AI...
```

---

## ğŸ› ï¸ Extending SYNAPSE

### Adding New Tools

Create a new tool in `Tools.py`:

```python
@tool
def my_custom_tool(query: str) -> str:
    """Description of what your tool does"""
    # Your implementation
    return result
```

Register it in the tool list:

```python
tools = [web_search, stock_price, my_custom_tool]
```

### Customizing the LLM

Modify `Backend.py` to use a different model or provider:

```python
from langchain_openai import ChatOpenAI

model = ChatOpenAI(model="gpt-4", temperature=0.7)
```

---

## ğŸ”® Roadmap

### Coming Soon

- [ ] ğŸ’¾ **SQLite-based persistent memory** â€” Long-term conversation storage
- [ ] ğŸ“š **RAG integration** â€” Document Q&A and knowledge retrieval
- [ ] ğŸ”Œ **MCP server support** â€” Model Context Protocol integration
- [ ] ğŸ§° **Extended tool library** â€” Weather, news, calculations, and more
- [ ] ğŸ¨ **Theme customization** â€” Dark mode and custom color schemes
- [ ] ğŸ“Š **Analytics dashboard** â€” Conversation insights and usage stats
- [ ] ğŸŒ **Multi-language support** â€” Internationalization
- [ ] ğŸ”’ **Authentication** â€” User accounts and access control

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **Push** to the branch (`git push origin feature/AmazingFeature`)
5. **Open** a Pull Request

### Development Guidelines

- Follow PEP 8 style guidelines
- Add docstrings to new functions
- Update README for new features
- Test thoroughly before submitting

---

## ğŸ“ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

---

## ğŸ‘¤ Author

**Nabin**

- GitHub: [@Nabin68](https://github.com/Nabin68)
- LinkedIn: [Nabin Rouniyar](https://www.linkedin.com/in/nabin-rouniyar-86682726a/)

---

## ğŸ™ Acknowledgments

- [LangChain](https://www.langchain.com/) â€” For the incredible LLM framework
- [LangGraph](https://langchain-ai.github.io/langgraph/) â€” For graph-based agent orchestration
- [Cohere](https://cohere.com/) â€” For powerful language models
- [Streamlit](https://streamlit.io/) â€” For the beautiful UI framework

---

## ğŸ“ Support

If you encounter any issues or have questions:

- ğŸ› [Open an issue](https://github.com/Nabin68/synapse-ai/issues)
- ğŸ’¬ [Start a discussion](https://github.com/Nabin68/synapse-ai/discussions)
- ğŸ“§ Email: nabingupta68@gmail.com

---

<div align="center">

### â­ Star this repo if you find it helpful!

**Made with â¤ï¸ by Nabin**

</div>
